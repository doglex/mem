---
date: 2017-10-08 14:47
status: public
title: 【操作系统】进程、线程以及协程
---

并发编程将软件看做任务和资源的组合——任务之间竞争和共享资源，当资源**满足时执行任务**，否则等待资源。

只是为了提高资源利用率，在**操作系统**层面提供支持。

## I、并发和并行

**并发**(Concurrent)的关键是你有乱序(甚至从中切换)处理多个任务的能力，不一定要同时。(处理顺序可以打乱)
**并行**(Parallel)的关键是你有同时处理多个任务的能力。(任务可以分解)

注：并发和并行都可以多线程，单CPU是并发，多CPU是并行。

## II、进程、线程和协程

###一、进程和线程的概念

1.**进程**是**CPU资源分配**的最小单位，**线程**是**CPU调度**的最小单位。（之前的操作系统没有线程）。

2.**进程(Process)和线程(Thread)都是一个时间段的描述，是CPU工作时间段的描述，不过是颗粒大小不同，线程细化了而已。**

3.线程的**生命周期**的五种状态：New、Runnable、Running、**Blocked阻塞**（Waiting、Locked、Sleeping）、Dead。

- Blocked阻塞可能有三种情况：Locked由Lock队列获取顺序，Waiting为执行了wait()方法后等待其他线程，Sleep()定时等待或者join()方法合并为子线程。
- New和Blocked状态结束后进入Runnable等待Running。

4.线程类型：主线程(创建进程时就有，一般最后关闭)，子线程，**守护线程**(daemon thread，守护其他的线程的线程，比如垃圾回收线程，等前台线程都退出才退出)，前台线程(不是守护线程的线程)。

5.**协程**(Coroutine,微线程)：

- 切换调度是程序员控制的，不像**多线程和多进程那样由操作系统调度**。
- 在Python中可以通过生成器中的yield轻松实现生产者消费者。
- **极高的执行效率**。一方面没有线程切换，通过程序的**逻辑设计跳转**始终在一个线程中，也**不需要加锁**，没有了资源竞争。
- 多进程+(各个进程下)协程既能利用多CPU，也能有很小的开销。

### 二、线程安全

1.**原子性**：要么一起不执行，要么一起执行。

比如执行到一半，寄存器上的值又被另一个线程覆盖了，那样就不安全了。

2.**一致性**:一个函数被多个并发线程反复调用时，要一直产生正确的结果。

3.线程安全的解决办法：在共享(全局)变量上加锁。

4.**可重入性**:打断后回来能保证一致性。这个约束比线程安全要求更高，线程安全只要求一致性。

5.可重复性的实现：拷贝一份全局变量的值到本地。"并发"程序显然要求可重入。



### 三、多线程和多进程

1.多进程和多线程都可以利用多CPU(但Python中有GIL因此一个进程下的多线程只能利用一个核)。

2.死锁：在线程间共享多个资源的时候，如果两个线程分别占有一部分资源并且同时等待对方的资源，就会造成死锁。

3.同一进程下的多个线程共享资源：所有进程的数据(而进程是资源分配的最小单元)，包括全局堆、全局变量、静态变量、文件、进程代码段、进程打开的文件描述符、信号的处理器、进程的当前目录、进程的用户ID和进程的组ID。因此**线程切换的开销相对于进程切换是小的**。

4.线程间独有的资源：栈和局部堆(线程的堆栈)、寄存器副本(寄存器组的值)、线程ID、错误返回码、线程的信号屏蔽码、线程优先级。

5.进程间通信（IPC）七种方式：

- 管道(Pipe)：只能半双工，数据单向流动。无名管道只能在父子进程中，有名管道(Named Pipe)可以无亲缘关系。
- 信号量(Semophore)：是一个计数器，作为锁机制，控制多个进程对共享资源的访问。
- 消息队列(Message Queue)：消息的链表。
- 信号(Signal)：通知接收进程某个事件已经发送。
- 共享内存(Shared Memory)：是最快的IPC。
- 套接字(Socket)：可以跨平台。

6.进程间通信(IPC)的四种技术:

- 消息传递(管道、FIFO、POSIX、System、消息队列)
- 同步(互斥锁、条件变量、读写锁、文件和记录锁、POSIX、System、信号灯)
- 共享内存(匿名共享内存区、有名POSIX、共享内存区，有名System)
- 过程调用(Solaris门、Sun RPC)

##III、Python支持

### 一、多线程

Python虚拟机使用GIL（Global Interpreter Lock，全局解释器锁）来互斥线程对共享资源的访问，只能利用单核。**GIL会把多线程序列化，来阻止线程并发。**。模块底层的有thread、封装好的threading、Queue(实现了多生产者多消费者)，第三方有Stackless Python、greenlet、gevent(和requests结合为grequests)等提供协程。

1.threading模块

提供了Thread(包括getName、isAlive、isDeamon、join、run、setName、setDeamon、start等方法)、Timer(等等一段时间后开始的Thread)、Lock锁、RLock(可重入锁，有一个计数器可以让单线程多次金融锁)、Condition条件变量(等待其他线程的条件)、Event(通用的条件变量，多个线程可以等待某个事件发生，在事件发生后，所有的线程都被激活)、Semaphore(为等待锁的线程提供一个类似“等候室”的结构)、BoundedSemaphore( 与Semaphore类似，但不允许超过初始值)

2.**可以考虑协程gevent来提高性能**

- 关键在于猴子补丁中 thread和socket不能覆盖掉标准库的，monkey是给python3用的。
- 每个进程中协程数可以从100到10 万都可以，看CPU占用。http://stackoverflow.com/questions/8678307/gevent-monkeypatching-breaking-multiprocessing

3.**在GIL下多线程仍然是有用的。在 I/O 密集型任务中，由于等待I/O响应的时间(GIL释放)比CPU计算时间长得多，所以在I/O密集型操作中，多个线程之间有效利用了I/O等待的时间，从而达到了并行的效果。**

### 二、多进程

Python在**计算密集型**任务中，必须考虑多进程，因为多线程实际上无用了。

**可以考虑C动态库(native方法)或者外挂一个shell或者内置的multiprocessing模块。**

1.multiprocessing模块

- Pool  是进程池(对于单核的CPU只能启动线程池，若启动进程池会跳出，线程池只能利用一个CPU)
- from multiprocessing.pool import ThreadPool   是进程池
- from multiprocessing.dummy import Pool  是线程池
- multiprocessing.Manager提供了多进程可以直接共享的list,dict,Namespace,Lock,RLock,Semaphore,BoundedSemaphore,Condition,Event,Queue,Value和Array。

2.第一个坑，参数坑

args后必须要有逗号，确认是元组，而且是可序列化的。

2.第二个坑，函数坑

multiprocessing 必须要求是函数外的函数做target，不能是同一层里的(命名空间问题)，target不能有装饰器。不然不能序列化

```
pickle.Pickl ingError: Can't pickle <function worker at 0x00000000026EC0B8>: it's not found as __main__.worker
```

3.第三个坑，join()

要在所有进程start()之后，因为第一个join()就阻塞了主线程。

```python
ts = []
for x in range(8):
  ts.append(Down(x,queue))
  ts[-1].start()
[t.join() for t in ts]
不能优化为
ts = []
for x in range(8):
  ts.append(Down(x,queue))
  ts[-1].start()
  ts[-1].join()
```

4.第四个坑，文件描述符

比如数据库、日志文件的操作和设备的访问是在父进程的基础上(直接fork())的，因此最好是重新初始化这些连接。

### 三、架构技巧

1.**IO(磁盘IO和网络IO)密集型**使用多线程和多进程都可以。

2.**计算CPU密集型**使用多进程+协程。

3.进程数使用CPU的线程数的倍数，比如2核4线程，就用4，400。

### 四、代码示例

```python
from multiprocessing import Pool
import gevent
from gevent import monkey
monkey.patch_all(thread=False,socket=False)
from gevent.queue import Queue
from gevent.threadpool import ThreadPool

class X:
    def __init__(self,name='x',):
        self.name = name
    def worker(self,x):  #with output
        result='5'  
        x + 2
        return result
    def eat_with_queue(self,ks,gcores=100):
        tasks=Queue(items=ks)
        def worker_with_queue():  #with output
            while not tasks.empty():
                self.worker(1)
        gPool=ThreadPool(maxsize=gcores)
        for _ in list(range(100)):
            gPool.spawn(worker_with_queue)
        gevent.wait()
        print("all done")

    def eat_with_multi(self,ks,mcores=4,gcores=100):
        mpool=Pool(processes=mcores)
        for kt in ks:
            mpool.apply_async(self.eat_with_queue,args=(kt,gcores))
        mpool.close()
        mpool.join()
```





参考资料：

https://www.zhihu.com/question/33515481?sort=created

https://www.zhihu.com/question/25532384

http://blog.csdn.net/maliao1123/article/details/53735001

http://www.speedycloud.cn/zh/news/company/20150923-126.html