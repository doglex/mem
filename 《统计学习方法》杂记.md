---
date: 2017-08-15 22:43
status: public
title: 《统计学习方法》杂记
---

### A、统计学习

1.特点：

- 基于计算机网络
- **数据驱动**
- 目的是**预测与分析**
- 重点是『方法』    

个人理解：更多应该是**业务驱动**，随着各种模型的成熟以及硬件的更新换代，更需要的是对业务本身的理解，更需要特征工程（虽然『深度学习』可以自动进行特征提取)。在一些硬件非常受限的情景（比如边缘计算）需要特殊考虑。『特征工程』决定了泛化能力的上限，『模型』本身也是一项『特征工程』，如果把y也当做一维特征，那么我们做的所有事不就是为了提取这个特征么？所以**Stacking的观点认为『目的即特征』**，y和X很难有一个确定的边界。当然，最好是『**无需建模**』，这就要求一个开箱即用的系统。

2.什么是学习？

系统通过执行某个过程改进它的性能。

3.统计学习的基本假设

同类数据在统计上具有一定的规律性，可以用概率加以处理。（即假设输入X与输出Y的的联合概率分布）

个人理解：这和『**协同过滤**』的想法差不多，人类的视角对『**重复性**』与『**相似性**』比较敏感。但是现实世界真的是『协同过滤』的吗，这是一个值得思考的问题。

4.分类：

- **监督学习**（surpervised learning）：有X,y; 分类（Classification离散目标）、回归（Regression拟合连续目标）、排名（Ranking）
- **非监督学习**（unsurpervised learning）：有X无y；聚类（Clustering）、去噪（自编码器Auto Encoding）
- **半监督学习**（semi-surpervised learning）：打了一部分标签
- **增强学习**（reinforcement learning）

个人理解：**虽然分类任务可以给出分类标签，但是无法给出标签的确信程度，回归任务退一步支持分类和排名，只需要给出分类阈值或者回归值比较，但是往往不如直接做分类。**

5.步骤

- 得到一个有限的训练数据集。
- 确定假设空间，即学习模型的集合。
- 确定模型选择的准则，即学习的策略。
- 确定学习的算法。
- 通过学习方法选择最优模型。
- 利用最优模型做分析或者预测。

个人理解：这只是一个『模型选择（Model Selection）的过程』，然而一个完整的Pipeline至少还包括**数据获取与清洗（Data Cleaning）、特征提取（Feature Extraction）、特征选择（Feature Selection）、模型选择（Model Selection）、交叉验证（Cross Validation）**。

6.监督学习

划分训练数据(trainning data)与测试数据(testing data)，划分输入空间、特征空间和输出空间。

个人理解：事实上，输入空间和特征空间很多时候难以严格区分，输出空间也是。而训练数据和测试数据大部分情况是一致的Pipeline。

7.统计学习三要素

**方法=模型+策略+算法**

- 模型：决策函数，参数空间（parameter space）。
- **策略：Objective=loss+penalty（= 经验风险+结构风险），最小化风险 = 最小化偏差bias+最小化方差variance的折衷**
  - 0-1损失 : f(y,f) = 0 if y == f else 1
  - 平方损失**MSE**:f(y,f) = power(y-f, 2)
  - 绝对损失:f(y,f) = abs(y-f)
  - 对数损失:f(y,P) = - logP(Y|X) 
  - 依概率分布求得Objective：离散的可以对各个样本上求平均损失，连续的可以求积分。#或者依出错的重要程度。
- 算法：最优化问题。凸优化（下降法、牛顿法、拟牛顿法）、网格搜索法。

8.模型评估与模型选择

- 训练误差和测试误差，测试误差小意味着**泛化能力**大（Generalization Ability）
- **过拟合**：overfitting，是追求训练误差小而导致测试误差大（追求经验风险而忽视结构风险，追求偏差而忽视方差）。**本质上是数据太少（或者说维度灾难），而模型太复杂**。解决方法可参考我之前的博客《【机器学习】过拟合问题》。
- 正则化（regularization）：添加结构风险项penalty（剃须刀原则）:L1(Lasso)、L2(Ridge)、L1+L2(ElasticNet)、剪枝、EarlyStoping、Batch-Normalization、Dropout等等。
- 交叉验证（cross validataion）：直接随机分两块（train0.7，test0.3）；或者分为K折交叉验证，一个Fold一个Fold验证；或者K=M，留一验证。

个人理解：一个问题，数据越大越好，一个任务的上界取决于数据，数据越大越趋近这个问题的上界，No Free Lunch（一方面是没有特定的模型可以解决所有问题，一方面是数据本身是分布是很重要的），那么做爬虫需要爬取多大的数据？当测试误差在承受范围内的数据量就可以了。

9.生成模型与判别模型

- 生成模型：先求得X与Y的联合分布，再求X条件下的Y概率。优点是第一可以还原出联合概率分布，第二当样本量增加时可以快速收敛于真实模型，第三存在隐变量时只能用生成模型。有朴素贝叶斯（Naive Bayes），隐马尔可夫模型（HMM）。
- 判别模型：直接求X条件下的Y概率。优点是第一直接面对预测时准确率更高，第二是简化了学习问题。有kNN，感知机，决策树，逻辑斯谛回归，最大熵模型，支持向量机，提升方法，条件随机场。

10.分类问题指标

- 混淆矩阵（confusion matirx）：FP，TP（True Positive），TN，FN
- 正确率m=1- error/total
- 精确率：Precision = TP/(TP+FP)
- 召回率:Recall=TP/(TP+FN)
- 调好均值：1/F1=1/2(1/P+1/R)  # 还有带beta的调合均值
- 多分类下：宏观精确率，微观精确率。。。
- ROC、AUC：比较适合看Ranking的质量
- 交叉验证、假设检验、t检验

11.标注问题（Tagging）

- 单词标注、序列标注
- 隐马尔可夫模型、条件随机场

12.回归问题：比如最小二乘法。

### B、线性模型Linear Model

线性模型的优点是简单易实现，缺点是仅适用于线性可分（或可拟合）数据，LR容易欠拟合。

#### 一、最小二乘法OLS/LSM

**（书上说）是无偏的（其概率分布的期望值就等于它所估计的参数），线性，最小方差，在欧式距离和高斯噪声的假设下是最优逼近点。**

- 目标式Objective:平方损失 Loss=power(y-f,2)，即MSE
- fx = wx+b    # w,x是相同维度向量
- 代入目标式，取极小值（另w和b的偏导都为0），可得闭式解。（因此是非常快的）。 

#### 二、岭回归RigdeRegression
Objective = Loss + (lambda)L2 （对参数的第二范式||w||，即平方约束）

求解可以用下降法。

#### 三、稀疏回归LassoRegression
Objective = Loss+ (lambda)L1(对参数的第一范式||w||，即绝对值约束)


求解可以用下降法。

#### 四、ElasticNet

Objective = Loss + （lambda）L1+(beta)L2

#### 五、逻辑斯谛回归（Logistic Regression,LR）

1.**虽然叫回归，实际上解决分类问题。**

容易**欠拟合**，原模型只能二分类，只适合（广义）线性问题。

 2.逻辑斯谛分布（指数族中的一种）

- 非负性
- 对称性
- S型（sigmoid）

```
分布F(x) = 1/(1+exp(-(x-u)/gamma))
密度f(x) = exp(-(x-u)/gamma))/(gamma x power(1+exp(-(x-u)/gamma),2))
```

验证一下：

```python
import numpy as np
import matplotlib
matplotlib.use("Tkagg")
import matplotlib.pyplot as plt
import math

x = np.linspace(-10, 10, 1000)
logistic_F = lambda x: 1.0 / (1 + math.exp(-x))
logistic_f = lambda x: math.exp(-x) / (1 + math.exp(- x)) ** 2
y = list(map(logistic_F, x))
z = list(map(logistic_f, x))
plt.figure(figsize=(8, 6))
plt.grid()
plt.plot(x, y, label="F(x) = 1/(1+exp(-(x-u)/gamma))")
plt.plot(x, z, label="f(x) = exp(-(x-u)/gamma))/(gamma x power(1+exp(-(x-u)/gamma),2))")
plt.legend(loc="best")
plt.ylim(0, 1.2)
plt.show()
```


![](~/1_logistic_distribution.png)


3.逻辑斯谛模型及参数估计

**是广义线性的**

![](~/2_IMG_20170813_165540.jpg)



4.最大熵原理

在所有可能的概率模型中，熵最大的模型是最好的模型。（类似于共振）

对未知的假设为等可能（即熵最大）是最合理的。

#### 六、感知机Perceptron及代码实现

1.感知机是一种**线性**分类模型（LR也是）。

在线性可分下是可证明是收敛的，存在多个解。

SVM要求结构风险最小，而他只要（找超平面wx=0）划分两类就可以了。

2.原理推导

约定：x填充一维1，式子不带b。

![](~/3_perceptron.jpg)

3.几个思考：

- 网上很多人说可以用牛顿法来下降（却没有说明具体的过程），但是其实这是一个线性问题，求二阶梯度是0，可能是要遇到问题的。线性无法表示异或。
- 如何快速判断是否线性可分（[TODO]以后研究）。
- 步长是否真的在各个分量上保持一致（注意是步长的维度，而不是梯度的各个方向，步长的各个维度与负梯度各个维度相乘得到了增量）。

4.程序实现
不使用numpy来实现。
```python
# coding=utf-8
from copy import deepcopy

class Perceptron:
    """ perceptron 感知机
    """

    def __init__(self, *args, **kwargs):
        self._x = None  # 训练集的特征向量集合x
        self._y = None  # 训练集的监督值集合y
        self.dimension = None  # 特征维度
        self.shape = None  # 训练集的形状
        self.w = None  # 权重向量
        self.learning_rate = None  # 学习步长
        self._cache_lambdaxiyi = None  # 缓存第i个数据的计算
        self.max_loop = None  # 最大尝试轮数
        self._history = []  # 记录历史的权重
        self.debugging = False
        if args:
            self.fit(*args, **kwargs)

    def _check(self):
        """ 检查数据合法性
        """
        if len(self._x) != len(self._y):
            raise ValueError("length of train_x and train_y not match")
        for xi in self._x:
            if len(xi) != self.dimension:
                raise ValueError("length of x not consistent")
            [self._check_float(xii) for xii in xi]
        [self._check_float(yi) for yi in self._y]

    @staticmethod
    def _check_float(x):
        """  检查数据类型是否是浮点型
        """
        if type(x) != float:
            raise ValueError("%s not float" % x)

    def _tail_one(self):
        """  对特征追加一维
        """
        for xi in self._x:
            xi.append(1.0)
        self.dimension += 1

    def _init_cache(self):
        """  初始化加速缓存
        """
        self._cache_lambdaxiyi = tuple(tuple(self.learning_rate * yi * xii for xii in xi)
                                       for xi, yi in zip(self._x, self._y))

    def _train(self):
        """ 执行训练过程
        """
        idx = 0
        count = 0
        loop = 0
        while 1:
            if count > self.shape[1]: break
            count += 1
            if self.debugging:  # 测试输出
                print(idx, count, self.w)
            idx = (idx + 1) % self.shape[1]  # 第i个样本点
            if idx == 0: loop += 1
            if loop >= self.max_loop: raise TimeoutError("reach max loop, may be inseparable")
            if self._is_error(idx):
                count = 0
                self._history.append(tuple(self.w))
                self._update(idx)
        self._history.append(tuple(self.w))

    def _is_error(self, idx):
        return round(self._y[idx] * self._vector_multiply(self.w, self._x[idx]), 1) <= 0.0

    @staticmethod
    def _vector_multiply(v1, v2):
        """ 向量点乘
        """
        return sum(map(lambda x1, x2: x1 * x2, v1, v2))

    @staticmethod
    def _vector_add(v1, v2):
        """ 向量求和
        """
        return list(map(lambda x1, x2: x1 + x2, v1, v2))

    def _update(self, idx):
        """ 执行权重更新操作
        :param idx:
        :return:
        """
        self.w = self._vector_add(self.w, self._cache_lambdaxiyi[idx])

    def fit(self, train_x, train_y, learning_rate=0.1, max_loop=1000, debugging=True):
        """ 输入训练数据进行训练
        :param train_x: <list<tuple<float [d]>>>  d维的训练数据集
        :param train_y: <list <float>>  1维的标签列表，与train_x一一对应
        :param learning_rate: 学习率
        :param max_loop: 最大迭代轮数
        :param debugging: 是否开启调试信息
        """
        self._x = deepcopy(train_x)  # 安全使用
        self._y = deepcopy(train_y)
        self.dimension = len(train_x[0])
        self.shape = self.dimension, len(self._y)
        self.learning_rate = learning_rate
        self.debugging = debugging
        self.max_loop = max_loop
        self._check()
        self._tail_one()
        self.w = [0.0 for _ in range(self.dimension)]
        self._init_cache()
        self._train()

    def _sign(self, x):
        return 1.0 if x >= 0 else -1.0

    def predict(self, test_x):
        """ 为测试数据预测二分类标签
        :param test_x: list< float [d]> 单个d维的测试数据
        :return: float 标签值
        """
        test_x = list(test_x)
        if len(test_x) != self.shape[0]: raise ValueError("shape not match")
        test_x.append(1.0)
        return self._sign(self._vector_multiply(self.w, test_x))


class Case:
    @classmethod
    def demo(cls):
        train_x = [[3.0, 3.0], [4.0, 3.0], [1.0, 1.0]]
        train_y = [1.0, 1.0, -1.0]
        perceptron = Perceptron(train_x, train_y, learning_rate=0.3, debugging=False)
        # perceptron = Perceptron()
        # perceptron.fit(train_x,train_y,learning_rate=0.3,debugging=False)
        test_points = [(1.0, 2.0), (-1.0, -2.0), (4.0, 4.0)]
        for point in test_points:
            print(point, perceptron.predict(point))

        # plot
        import matplotlib  # dynamic importing
        matplotlib.use("Tkagg")
        import matplotlib.pyplot as plt
        plt.figure(figsize=(8, 6))
        for point, color in zip(train_x, train_y):
            plt.scatter(point[0], point[1], c="r" if color > 0 else "g", marker="s")
        axis0, axis1 = list(zip(*train_x))
        axis0_max, axis0_min, axis1_max, axis1_min = max(axis0), min(axis0), max(axis1), min(axis1)
        import numpy as np
        x_scan = np.linspace(axis0_min - 1, axis0_max + 1, 100)
        for i, w in enumerate(perceptron._history[1:]):
            y_scan = [(w[0] * xi + w[2]) / - w[1] for xi in x_scan]
            plt.plot(x_scan, y_scan, label="update_" + str(i))
        plt.ylim(axis0_min - 1, axis1_max + 1)
        plt.legend()
        plt.grid()
        plt.show()

    @classmethod
    def demo2(cls):
        train_x = [[3.0, 3.0], [4.0, 3.0], [1.0, 1.0], [4.0, 3.1]]
        train_y = [1.0, 1.0, -1.0, -1.0]
        perceptron = Perceptron()
        perceptron.fit(train_x, train_y)


if __name__ == '__main__':
    # Case.demo2()
    Case.demo()
```
### C、EM算法

#### 一、EM原理

如果不含隐变量而能直接求解当然是最好啦，但是引入隐变量可能扩大一些假设空间，另外在具体的问题下可能必须引入隐变量。

含有隐变量的目标无法直接推导，只能退一步先求解一部分，再求解另一部分，这样迭代。

在E步求期望，在M步使得期望最大。

####二、EM推导

参考韩龙飞的博客  http://www.hanlongfei.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2015/08/12/em/


![](~/4_em.jpg)


####三、EM应用（K-means代码实现）

1.k-means聚类（非监督），在E步计算各个聚类中心，在M步重新划分cluster使得目标（可以是平均距中心距离、内散度外散度、最远距离等等）最小。k-means是一种探索性方案，因为k类需要讨论，初始值的影响也很大，也受限于数据分布的形状。

python实现

```python
# coding=utf-8
from copy import deepcopy
from random import sample

class Kmeans:
    """ K-means 聚类，目标是平均中心距离最小
    """

    def __init__(self, *args, **kwargs):
        self._x = None  # 内部存储的训练集
        self.dimension = None  # 训练集的维度
        self.shape = None  # 数据集形状
        self.n_clusters = None  # cluster的数量
        self.centers = None  # 聚类中心
        self._y = None  # 与self._x 一一对应的cluster id
        self._init_func = sample  # 指定初始化方案
        self.max_loop = None  # 最大迭代次数
        self.distance = self._squared_euclidean_distance  # 指定距离方案
        self.debugging = False  # 是否开启调试模式
        self.history = []  # 历史记录，仅在调试模式下追加数据
        if args or kwargs:  # 重定向初始化方法
            self.fit(*args, **kwargs)

    def _check(self):
        """ 检查数据合法性
        """
        for xi in self._x:
            if len(xi) != self.dimension:
                raise ValueError("length of x not consistent")
            [self._check_float(xii) for xii in xi]

    @staticmethod
    def _check_float(x):
        """  检查数据类型是否是浮点型
        """
        if type(x) != float:
            raise ValueError("%s not float" % x)

    def _init_clusters(self):
        """ 初始化聚类中心
        """
        centers = self._init_func(self._x, self.n_clusters)
        self.centers = {i: centers[i] for i in range(self.n_clusters)}

    def _squared_euclidean_distance(self, v1, v2):
        """ 欧式距离的平方，无须开方
        """
        return sum(map(lambda x1, x2: (x1 - x2) ** 2, v1, v2))

    def _re_cluster(self, idx):
        """ 重新分cluster
        :param idx: int, 第i个数据点
        :return: 新的clustet_id
        """
        return sorted([(self.distance(self._x[idx], center), k)
                       for k, center in self.centers.items()],
                      key=lambda x: x[0],
                      reverse=False)[0][1]  # todo:效率待优化到线性

    def get_clusters(self):
        """ 获取所有cluster
        :return: dict <int:list> 各个簇的字典
        """
        clusters = {i: [] for i in range(self.n_clusters)}  # 会不会有空的cluster，是可能的
        for x, y in zip(self._x, self._y):
            clusters[y].append(x)
        return clusters

    def _vector_center(self, vectors):
        """
        :param vectors: <list<list<float>>> 一个cluster内的所有点
        :return: list<float> 这些点的几何中心
        """
        return list(map(lambda x: sum(x) / len(x), zip(*vectors)))

    def _re_center(self):
        """
        :return: 更新所有cluster的几何中心
        """
        clusters = self.get_clusters()
        for k in clusters:
            clusters[k] = self._vector_center(clusters[k])
        self.centers = clusters

    def _train(self):
        """ 在有限迭代次数下 重新分cluster，更新各个cluster中心
        """
        loop = 0
        while 1:  # 1 is better than True
            loop += 1
            if loop > self.max_loop: break  # 出口条件1：达到迭代次数上限
            if self.debugging:
                # print(loop,self.get_clusters())
                self.history.append(self.get_clusters())
            not_re_centered = True
            for i in range(self.shape[1]):  # M步
                new_center = self._re_cluster(i)
                if self._y[i] != new_center:
                    self._y[i] = new_center
                    not_re_centered = False  # 出口条件2：这一轮没有更新中心位置，下一轮也无法更新了
            if not_re_centered: break
            self._re_center()  # E步

    def fit(self, x, n_clusters=3, max_loop=1000, debugging=False):
        """ 模型入口
        :param x: list<list<float>> 各个数据
        :param n_clusters: int 指定k个cluster
        :param max_loop: int 最大迭代次数
        :param debugging: boolean 是否开启调试模式
        """
        self._x = deepcopy(x)
        self.dimension = len(x[0])
        self.shape = self.dimension, len(x)
        self.n_clusters = n_clusters
        self.max_loop = max_loop
        self.debugging = debugging
        self._check()
        self._init_clusters()
        self._y = [0] * self.shape[1]
        self._train()

    def predict(self, xi):
        """ 预测单点分类
        :param xi: list<float> 待预测点
        :return: int cluster_id
        """
        if len(xi) != self.dimension: raise ValueError("length not match")
        return sorted([(self.distance(xi, center), k)
                       for k, center in self.centers.items()],
                      key=lambda x: x[0],
                      reverse=False)[0][1]  # todo:效率待优化到线性


def demo():
    x = [[100.0, 101.0], [102.0, 102.0], [117.3, 118.6], [-1.0, 1.2],
         [50.5, 50.7], [60.8, 60.9], [-100.0, -98.8], [-99.7, -99.2],
         [50.7, 52.8], [-2.0, -50.5], [-5.7, -10.6], [-60.6, -70.3], ]
    kmeans = Kmeans(x, n_clusters=3, debugging=True)
    # kmeans = Kmeans()
    # kmeans.fit(x,debugging=True)
    history = kmeans.history
    n_history = len(history)
    test_cases = [(-100.0, -200.0), (1.0, 5.6), (200.7, 199.9)]
    for case in test_cases:
        print(case, kmeans.predict(case))
    import matplotlib
    matplotlib.use("tkagg")
    import matplotlib.pyplot as plt
    plt.figure(figsize=(4, 3))

    for hi in range(n_history):
        plt.subplot(n_history, 1, hi + 1)
        for ci in range(3):
            data = history[hi][ci]
            if not data: continue
            xs, ys = list(zip(*data))
            plt.scatter(xs, ys, c="r" if ci == 0 else "g" if ci == 1 else "b")
            plt.grid()
    # plt.savefig("k_means.png",dpi=300)
    plt.show()
    print(history)


if __name__ == '__main__':
    demo()
```

运行结果

![](~/5_k_means.png)


2.高斯混合模型GMM
3.隐马尔可夫模型HMM
### D、凸优化与SVM

#### 一、什么是凸（视觉上的凹碗状）

参考下面四个博客

http://www.hanlongfei.com/%E5%87%B8%E4%BC%98%E5%8C%96/2015/05/26/hyperplane/

http://www.hanlongfei.com/%E5%87%B8%E4%BC%98%E5%8C%96/2015/05/22/convexset/

http://www.hanlongfei.com/%E5%87%B8%E4%BC%98%E5%8C%96/2015/09/24/cmu-10725-convexset/

http://www.hanlongfei.com/%E5%87%B8%E4%BC%98%E5%8C%96/2015/05/20/convexoptimization/

1.凸函数

> softmax = log(sum(kexp(aiT x+ bi))) 是凸函数

- 一阶梯度(也叫微分、偏导)单调不减
- 二阶梯度矩阵（海森矩阵）半正定（正定看惯性，化为规范型）
- 仿射不变性：若f(x)凸，那么f(Ax+b)也凸
- 严格凸函数最多一个最小值，任何极小值都是最小值。

2.仿射集、凸集与锥

![](~/6_convex_1.jpg)


- **若是仿射集，则必是凸集。**
- 空集、单点、实数域、点集是仿射集也是凸集。
- 一条直线是仿射集，若过原点是凸锥。
- 线段是凸集，不是仿射集（除非只有一个点）。
- 射线是凸集，不是仿射集，若x0为0，那么是凸锥。

3.**超平面**

是线性方程组的解  x| aT(x-x0) =0 

划分两个**半空间**，半空间是凸集，不是仿射集。

4.不改变凸性的运算

- 交集
- 仿射函数 f(x) = Ax+b
- 透视函数  R(n+1) - > R(n) : 通过规约变换或者归一化减小一个维度。

5.**真锥** = 点集 + 凸集 + 闭合 + 实心

真锥下的泛化不等式 x <= ky  <==>  y-x  belongto K

- 可加性 x <= ky, u<= ky   ==>  x+u <= ky
- 传递性 x <= ky, y<=kz  ==> x <= kz 
- 自反性  x<=ky, alpha > 0  ==> alphax <= alphaky
- 反对称性  x<=kx
- 极限保持性 多个x分量

6.极小值与最小值，**分割超平面理论**，支持超平面

#### 二、凸优化问题与技巧

参考博客

http://www.hanlongfei.com/%E5%87%B8%E4%BC%98%E5%8C%96/2015/05/20/convexoptimization/

http://www.hanlongfei.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2015/07/29/gradient/

http://www.hanlongfei.com/%E5%87%B8%E4%BC%98%E5%8C%96/2015/09/25/cmu-10725-optimization/

http://www.hanlongfei.com/convex/2015/10/02/cmu-10725-subgradidient/

http://www.hanlongfei.com/convex/2015/10/28/proximal/

1.凸优化问题

包括线性规划和二次规划问题，Lasso和SVM的优化都可以认为凸优化问题

![](~/7_convex_2.jpg)


2.凸优化技巧

一阶优化、变形优化、部分优化

![](~/8_convex_3.jpg)


#### 三、凸优化方法：下降法

- 最速下降法
- 牛顿下降法
- 动态步长 BackTracking Line Search

![](~/9_gradient_1.jpg)


- 次梯度
- 近似梯度

![](~/10_gradient_2.jpg)


- Nesterov 通过冲量加速，但是会有一些ripple。实际一般是用warm start不断收敛lambda i，作网格搜索。

#### 四、对偶问题

**问：为什么要将问题转换为对偶？**

**答：第一对偶问题的约束形式更加简单，第二是当原问题难以直接解决时对偶问题往往有更小的求解复杂度，第三是对偶问题直接支持的kernel trick。**

参考博客

http://www.hanlongfei.com/convex/2015/11/08/kkt/

http://www.hanlongfei.com/convex/2015/11/05/duality/

##### 第一、线性规划对偶问题

由线性规划引入lagrange乘子，紧致下界。


![](~/11_dual_1.jpg)

##### 第二、二次规划对偶问题


![](~/12_dual_2.jpg)

##### 第三、SVM的对偶问题

![](~/13_dual_3.jpg)


#####第四、KKT条件（强对偶的充要条件）

- 四个条件：稳定性，松弛性，原问题可行性，对偶可行性。
- KKT是强对偶（对偶间隙为0）的充要条件。

![](~/14_KKT.jpg)


##### 第五、SVM与KKT

**KKT条件解释了为什么SVM分类器仅由支持向量决定，而跟远离边界的点无关。**


![](~/15_KKT_SVM.jpg)

#### 五、SVM（支持向量机）原理

1.特点

- 间隔最大（结构风险最小）
- 核技巧（Kernel trick，内积引入对偶形式非常方便，可以将非线性问题转为线性问题）
- 损失：等价于Hinge Loss 合页损失
- 优化：凸二次规化，快速算法SMO（利用启发式下降）

2.优点：存储小（只需要存储支持向量），适用于线性和非线性，性能好（引入核被认为和一层神经网络），适用与分类和回归（SVR）。

3.缺点：需要手工选取核（根据经验），原始的只能二分类。

#####第一、线性可分SVM（硬间隔最大化）

SVM = Perceptron+结构风险最小

![](~/16_svm_1.jpg)


##### 第二、软间隔最大化

不完全线性可分（在近处有少量Outlier），可引入松弛变量和惩罚因子。


![](~/17_svm_2.jpg)

##### 第三、合页损失函数HingeLoss

SVM的最优化问题可以等价为合页损失最优化


![](~/18_hingeloss.jpg)

#####第四、核技巧

![](~/19_kerneltrick.jpg)


#### 六、SMO序列最小优化算法

**启发式**的SVM快速算法，**启发式下降**。

##### 第一、SMO原理

![](~/20_smo_1.jpg)


#####第二、SMO下降法

![](~/21_smo_2.jpg)

##### 第三、SMO步骤

![](~/22_smo_3.jpg)


##### 第四、SMO代码实现（Python版）

具体使用可参考我的github仓库https://github.com/Dogless-plus/ALGs/tree/master/MachineLearning/SVM

```python
# coding=utf-8
# todo @dogless： 增加序列化和反序列化接口
# todo @dogless:  添加更多核函数
from copy import deepcopy

class SMO:
    """ SMO模型
    """

    def __init__(self, *args, **kwargs):
        """
        :param args: 重定向到fit方法的位置参数
        :param kwargs: 重定向到fit方法的关键字参数
        """
        self._x = None  # 内部存储的训练数据或者支持向量
        self._y = None  # 内部存储的训练数据的监督值或者支持向量的监督值
        self.dimension = None  # 数据的维度
        self.shape = None  # 训练数据的形状或者支持向量的形状
        self.max_loop = None  # 最大迭代次数
        self.debugging = False  # 是否开启调试模式
        self.a = None  # 各个样本点或者支持向量的权重
        self.b = None  # bias平面偏移
        self.E = None  # 残差列表
        self.C = None  # 惩罚因子
        self.kernel = None  # 核函数的挂载入口
        self.cache_kernel = None  # 缓存核函数值加速迭代
        self.tolerance = None  # 允许继续迭代的最小差值
        self._support_vector_x = []  # 临时支持向量列表
        self._support_vector_y = []  # 临时的监督值列表
        if args or kwargs:  # 将构造器同时作为训练的入口
            self.fit(*args, **kwargs)

    def _check(self):
        """ 检查数据合法性
        """
        if len(self._x) != len(self._y):
            raise ValueError("length of train_x and train_y not match")
        for xi in self._x:
            if len(xi) != self.dimension:
                raise ValueError("length of x not consistent")
            [self._check_float(xii) for xii in xi]
        [self._check_float(yi) for yi in self._y]

    @staticmethod
    def _check_float(x):
        """  检查数据类型是否是浮点型
        """
        if type(x) != float:
            raise ValueError("%s not float" % x)

    def _linear_kernel(self, i, j):
        """ 线性核
        :param i: int 左向量
        :param j: int 右向量
        :return: float 线性核函数值
        """
        return sum(map(lambda a, b: a * b, self._x[i], self._x[j]))

    def _init_cache_kernel(self):
        """ 缓存核函数值
        """
        cache_kernel = dict()
        for i in range(self.shape[1]):
            for j in range(self.shape[1]):
                cache_kernel[(i, j)] = self.kernel(i, j)
        self.cache_kernel = cache_kernel

    def _get_residual(self, i):
        """ 计算残差
        :param i: int 第i个样本点
        :return: float 残差
        """
        y_predict = sum(self.a[j] * self._y[j] * self.cache_kernel[(j, i)]
                        for j in range(self.shape[1])) + self.b
        return y_predict - self._y[i]

    def _update_E(self):
        """ 更新残差列表
        """
        for i in range(self.shape[1]):
            self.E[i] = self._get_residual(i)

    def _is_against_kkt(self, i):
        """ 是否违背了KKT条件
        :param i: int 第i个样本点
        :return: boolean  是或者否
        """
        return (self.a[i] < self.C and self._y[i] * self.E[i] < -self.tolerance) or \
               (self.a[i] > 0 and self._y[i] * self.E[i] > self.tolerance)

    def _update(self):
        """ 单轮参数更新(单轮训练)，更新式都是书上的公式，更新a和b还有残差列表
        :return: 是否需要再一轮更新
        """
        is_updated = False
        for i in range(self.shape[1]):
            if not self._is_against_kkt(i): continue
            for j in range(self.shape[1]):
                if j == i: continue
                eta = self.cache_kernel[(j, j)] + self.cache_kernel[(i, i)] - 2 * self.cache_kernel[(i, j)]
                if eta <= 0: continue
                aj_new = self.a[j] + self._y[j] * (self.E[i] - self.E[j]) / eta
                if self._y[i] == self._y[j]:
                    L = max(0, self.a[j] + self.a[i] - self.C)
                    H = min(self.C, self.a[j] + self.a[i])
                else:
                    L = max(0, self.a[j] - self.a[i])
                    H = min(self.C, self.a[j] - self.a[i] + self.C)
                aj_new = H if aj_new > H else L if aj_new < L else aj_new
                if -0.001 < self.a[j] - aj_new < 0.001: continue
                ai_new = self.a[i] + self._y[i] * self._y[j] * (self.a[j] - aj_new)
                b_new1 = self.b - self.E[i] - self._y[i] * self.cache_kernel[(i, i)] * (ai_new - self.a[i]) - \
                         self._y[j] * self.cache_kernel[(j, i)] * (aj_new - self.a[j])
                b_new2 = self.b - self.E[j] - self._y[i] * self.cache_kernel[(i, j)] * (ai_new - self.a[i]) - \
                         self._y[j] * self.cache_kernel[(j, i)] * (aj_new - self.a[j])
                self.b = b_new1 if 0 < ai_new < self.C else b_new2 if 0 < aj_new < self.C else (b_new1 + b_new2) / 2.0
                self.a[i] = ai_new
                self.a[j] = aj_new
                self._update_E()
                is_updated = True
        return is_updated

    def _train(self):
        """ 执行多轮训练，训练不成功应该直接报错
        """
        for loop in range(self.max_loop):
            if not self._update():
                return
            if self.debugging:
                print(loop, self.a, self.b)
        raise ValueError("reach max loop limit")

    def _mk_support_vectors(self):
        """ 将内部存储压缩至支持向量
        """
        a_new = []
        for i, v in enumerate(self.a):
            if v > 0:
                self._support_vector_x.append(self._x[i])
                self._support_vector_y.append(self._y[i])
                a_new.append(v)
        # print(self.shape)
        self._x = self._support_vector_x
        self._y = self._support_vector_y
        self.a = a_new
        self.shape = self.shape[0], len(self._x)
        # print(self.shape)

    def fit(self, x, y, C=10, kernel="linear", max_loop=1000, tolerance=0.00001, debugging=False):
        """ 用外部数据拟合出一个二分类的svm
        :param x: list<tuple<float>> 相同维度的训练数据点列表
        :param y: list<float> 与x同样长度的监督值列表
        :param C: float 惩罚因子，惩罚约大意味着对outlier的容忍度越小
        :param kernel:  指定核函数名，核函数做成可插拔的。默认是线性核『linear』
        :param max_loop: 最大迭代轮数，默认1000.
        :param tolerance: 最小更新量（针对残差），默认0.00001
        :param debugging: 是否开启,若开启，将在stdout输错更多调试信息。默认关闭。
        """
        self._x = deepcopy(x)
        self._y = deepcopy(y)
        self.C = C
        self.tolerance = tolerance
        self.debugging = debugging
        self.max_loop = max_loop
        self.dimension = len(x[0])
        self._check()
        self.shape = self.dimension, len(x)
        self.a = [0.0] * self.shape[1]
        self.b = 0.0
        self.kernel = self._linear_kernel if kernel.lower() == "linear" else None  # TODO: more kernel
        self._init_cache_kernel()
        self.E = [0.0] * self.shape[1]
        self._update_E()
        self._train()
        self._mk_support_vectors()

    def predict(self, x):
        """ 预测新数据
        :param x: 待预测的数据点
        :return: 预测值 1.0 或者 -1.0
        """
        if len(x) != self.dimension: raise ValueError("length not match")
        self._x.append(x)
        y = sum(self.a[j] * self._y[j] * self.kernel(j, -1) for j in range(self.shape[1])) + self.b
        self._x.pop()
        return 1.0 if y >= 0 else -1.0


def case():
    """ 测试demo
    """

    def load_data(filename):
        with open(filename, "rt") as f:
            lines = f.readlines()
        xs, ys = [], []
        for line in lines:
            line = line.strip().split()
            xs.append(tuple(float(xi) for xi in line[:-1]))
            ys.append(float(line[-1]))
        return xs, ys

    xs, ys = load_data("train.tsv")
    smo = SMO()
    smo.fit(xs, ys, debugging=True)
    # for xi,yi in zip(xs,ys):
    #     print(smo.predict(xi),yi)


    import matplotlib
    matplotlib.use("tkagg")
    import matplotlib.pyplot as plt
    plt.figure(figsize=(8, 6))
    # 绘制训练数据
    for xi, yi in zip(xs, ys):
        plt.scatter(*xi, c="r" if yi > 0 else "g", marker="s", s=50)
    # 绘制两个半平面
    import numpy as np
    x_scan = np.linspace(10, 90, 50)
    y_scan = np.linspace(10, 90, 50)
    for xi in x_scan:
        for yi in y_scan:
            z = smo.predict((xi, yi))
            print(xi, yi, z)
            plt.scatter(xi, yi, c="r" if z > 0 else "g", marker="x", s=10)
    plt.grid()
    plt.savefig("smo.png", dpi=300)
    plt.show()


if __name__ == '__main__':
    case()
```

运行效果：

![](~/23_smo_4.png)


### E、集成方法

XGBoost应该是很厉害的模型，第二层用LR做Stacking是比较流行的做法。

包括Bagging(RF)、Boosting(Adaboost、GBRT（XGBoost））等，请参考我之前写的两篇博客。

《【机器学习】集成方法整理》http://dogless.farbox.com/post/github/-ji-qi-xue-xi-ji-cheng-fang-fa-zheng-li

《XGBoost:Boosted Trees整理》http://dogless.farbox.com/post/github/-ji-qi-xue-xi-xgboost_boosted-treeszheng-li

### F、决策树

1.问：上面**集成方法**里大量使用**CART回归树**，为什么？

个人理解：第一，因为树的**scalability**，树的扩充和剪枝(prunning)是很灵活的，也适用于混合的离散型和连续型数据；第二，树对缺失值不大敏感，可以简单的解决**缺失值**问题；第三，树对大量**特征**（可能容易导致维度灾难）是友好的，一方面本身在分裂的时候进行特征选择，另外可以通过对特征加随机噪声看看抗扰动性来衡量特征重要性；第四，树的实现是简单的；第五，树本身是一种**级联(Modularization)**模型，而级联本身是深度学习的基础（Deep is better than fat. 原因，可以用更少的单元表示一样大的空间）。至于用CART而不是香农熵，是因为基尼指数（两次取得同一个类别的概率）计算简单而且可以近似香农熵。

2.特点

- 结点（**内部结点**（feature+split）+**叶结点**（class））+有向边
- **IF-THEN规则集合**：划分的特征空间互不相交。（思考，如何设计一个划分重叠的，即『模糊』决策树）
- 适用于多分类，也适用于回归。
- 找最优的决策树的NP完全问题，可能要**启发式方法。**
- 决策树训练  <==> 估计条件概率模型。
- 训练的三步：**特征选择，树的生长，剪枝。**

#### 一、多叉决策树

##### (一)特征选择（消除『不确定性』，相当于『去噪』）

不确定性减得更小，说明对这个类的确信度越高，意味着更好的分类能力。

经典的有三种分裂准则。

(1).**信息增益**（**ID3**）多叉树

- 香农熵 H(X) = - sum(p x logp)
- 条件熵 H(Y|X) = sum(p x H(Yi|X=Xi))
- 信息增益 g(D,A) = H(D) - H(D|A) = H(D) - |Di| / |D| x H(Di | Ai)   >= 0     // argue feature Ai

注：信息增益也称互信息，若X，Y独立，那么H(Y) = H(Y|X) ，互信息为0，否则H(Y) > H(Y|X).

(2).**信息增益比**（**C4.5**）多叉树

- 以信息增益划分将严重偏向于选择取值较多的特征（比如id那一列），需要减小取值量的影响。


- r(D,A) = g(D,A) / H(splits) ,H(splits) = sum(|Di|/|D|log(|Di|/|D|))


(3)**CART** (classification and regression trees)**二叉**分类树的**基尼指数(Gini Index)**

Gini (D) = 1- sum(power(p,2))   // 两次抽取不是同一类的概率

// 二分类的话退化为 1- power(p,2) - power(2-p,2) = 2p(1-p)

Gini(D,A) = |D1|/ |D| Gini(D) 

gain(A|D) = Gini(D) - min(Gini(A,D))   //  argure feature Ai and the best split point of Ai

注：基尼指数数值上可以近似于熵，且计算简单。基尼指数本身可以表示可能的误差程度（不确定程度）。

##### (二)递归构造决策树：生长

终止分裂时生成叶节点。

终止条件：

- 所有实例是同一类。（或者置信度足够，这类在这个结点中占绝大多数。或者说基尼指数足够小。）
- 没有更多的特征用来区分。（每一次分裂都需要消耗掉一个特征）
- (optional)信息增益小于阈值。（分裂带来的增益很小，却需要增大一个复杂度）
- (optional)达到最大深度。（几乎不用计算的指标）
- (optional)这个节点的样本数小于预定值。（比如用于CART回归树中）

#####(三)剪枝(prune)

个人理解：**随机森林**一般不剪枝或者直接使用树桩，因为特征的随机选择（**列采样**，这种技术也被XGBoost采用）**引入是随机性减小了过拟合**。而**强大数定理**又保证了随着树的数量的增加不容易导致过拟合，**虽然模型看起来变复杂**了。注：再提一下**随机性**，不仅有利于减小过拟合(比如列采样，比如dropout)，还有利于跳出局部最小点（比如随机下降，比如模拟退火）。**个人认为随机性也可以看成是一种没有办法之办法，启发式也是没有办法的办法，动态规划也是没有办法的办法，过度的鼓吹这些方法如果在可以用确定方法直接解决的问题上反而导致了复杂度**。

(1)**为什么要剪枝**？

决策树模型在训练过程中为了使得树模型更好地拟合（fit）上训练数据，往往导致模型过于复杂，从而导致**过拟合**(overfitting)，即在训练集上的性能好但是在预测集上的性能(metrics)差。那么需要降低模型复杂度,可以通过减少一些分裂（叶节点）来降低模型复杂度。

// 个人理解：更好地拟合是降低经验风险(降偏差bias)，但是同时带来了结构风险(增加了方差variance)。

(2)剪枝标准：

- 利用OOB等划分出的验证集进行交叉验证，
- Chi-Square（卡方检验，TODO）
- 最小编码长度MDL等。

(3)剪枝方案：

- REP(Reduced Error Pruning)错误率降低剪枝。还是容易过拟合，用得少。
- PEP悲观剪枝（TODO），用得多，在实践上的精度高。
- **CCP**(Cost-Complexity Pruning) 代价复杂度剪枝。相当于写一个Object = Loss + Omega。 可以参考下文的CART剪枝。

(4)**预剪枝**(pre pruning)和**后剪枝**(post pruning)的区别

预剪枝在树的生长时候阻止了继续分裂（early-stopping），后剪枝在树生长完全后回过头来剪枝。预剪枝阻止了很多生长可能，计算量小但是是局部优解，后剪枝计算量巨大打算更接近全局最优解。

(5)举例

Object(a,T) = sum(NtHt(T)) + a|T|  //T表示叶子节点，前向是带权重的叶子节点上熵的和，后项是叶子节点数量

若退回到父节点能使Object更小或者不变，那么考虑裁剪掉这些叶节点，可以局部地进行，可以动态规划，直到不能再剪枝。

####二、CART二叉回归树（最小二乘回归树）

输出结果是回归值（连续值而不是分类标签）。

1.树的等价形式是一个阶梯函数  f(x) = CmI(x belongto Rm)

2.平方误差Loss = sum(yi - Cm)，使得平方误差最优的解是Cm= avag(T)

3.寻找每个分裂的方法  min <argue feature,split>  { min Loss(T1) + min Loss(T2)}

那么每次分裂都需要遍历**各个特征**（维度）的**各种划分**情况。不妨将特征数据先排序（因为跨序划分到同一类可以证明是平方误差更大的），如果用于森林的话还可以复用。

注：停止条件可以参考上一小节。

####三、CART二叉分类树

1.如何做到二叉：**是否取这个值**，比如一个feature『颜色』，有RGB三种取值，那么是否取R就可以划分为两类,那么就有3个split了。

2.分裂方案：min<argue feature,split> {max gain_Gini(A|D)} or stop.

#### 四、CART剪枝（代价剪枝方法）

1.代价Loss(a, T)=C(T)+a|T|  // T为任意内部节点为根的子树

其中C(T)可以是训练集上的误差，比如基尼指数

2.**a变小时使得树偏大，a变大时使得树偏小。因此，可以调节a的大小来递归地剪枝。**

3.对于任意内部节点 t 为根的子树，t表示当前节点不再分裂，Tt表示分裂到完整树T0。

Loss(a,t) = C(t) + a

Loss(a,Tt) = C(Tt) + a|T|

当a比较小的时候，有Loss(a,Tt) < Loss(a,t)

当a继续增大到 Loss(a,Tt) = Loss(a,t)便有理由在t处剪枝了。

此时，a = [C(t) - C(Tt)] / [|Tt| -1].

4.对每个内部节点都可以计算g(t) =  [C(t) - C(Tt)] / [|Tt| -1],越顶层的g(t)越大。

每轮可以去裁剪g(t)最小的内部节点，这样不断增大a的阈值（比a小的内部节点都被裁剪）就可以得到一堆候选树，直到a够大以裁剪到根节点Tn。候选树{T0,T1,T2,…,Tn},可以利用独立的验证集的预测性能来选取最优的候选树。

5.步骤小结：

从小到大开始选择a，不断剪枝生成候选树。利用交叉验证法，在候选树中找到最优树。
### G、k近邻法（kNN）

1.思路：近朱者赤，近墨者黑。（其实仍然是一种基于相似性的协同过滤）

2.三个问题：

- 距离选择：欧式距离（Lp距离的第二范式）、马氏距离、Jaccard距离、余弦相似度、皮尔逊相关系数等。
- k值选择：k越小，模型复杂度越大，越容易过拟合。k一般不超过20，k=1时是最近邻算法。
- 分类决策：0-1损失下的经验风险最小化等价于多数表决。（还是需要假设一下数据的均匀分布的吧）

3.**免训练模型**，意味着直接判决。为了加速索引，使用kd-tree和ball-tree来减小搜索范围。

 4.代码实现（试一下可读性差和效率都差的代码）

```python
from functools import partial
from collections import Counter

distance = lambda x, y: sum(map(lambda a, b: (a - b) ** 2, x, y))
nearest_k = lambda test, train_x, k=1: list(
    zip(*
        sorted(
            map(lambda a:
                (a[0], (partial(
                    distance, y=test)(a[1]))),
                enumerate(train_x)),
            key=lambda x: x[1],
            reverse=False)))[0][:k]
predict = lambda test, train_x, train_y, k=1: sorted(
    Counter(train_y[idx] for idx in nearest_k(test, train_x, k)).items(),
    key=lambda x: x[1],
    reverse=True)[0][0]

train_xy = [((2.1, 3.0), 1.0), ((1.2, 3.3), 1.0), ((1.2, 1.5), -1.0),
            ((-1.6, 1.5), 1.0), ((1.4, 2.3,), -1.0), ((1.6, 1.7), 1.0)]
print(predict((0.3, 0.0), *zip(*train_xy), 3))
```

5.拓展：

- 原算法是k个近邻，考虑一下一定距离范围的近邻，不限定多少个。
- kNN的错误率不超过最优贝叶斯分类器的两倍。

### H、朴素贝叶斯（Naive Bayes）

####一、朴素贝叶斯原理

1.贝叶斯思想：**后验 = 似然 x 先验**  (比如LR+L2 = MLP + GWN)

2.**为何朴素：求解条件概率(似然)时假设各个属性独立。**这是一个很强的假设。

3.朴素贝叶斯模型（研究Y）

- 先验分布P(Y)

- 后验分布P(Y|X)

- 由联合概率推导 P(X,Y) = P(X) P(Y|X) = P(Y) P(X|Y)  // 贝叶斯公式

- 后验概率  P(Y|X) =  P(Y) P(X|Y) / P(X)    

  其中P(Y)是先验，后面相乘是似然

  其中分母P(X)在一个特定的x下讨论各个y时是一致的因此可以忽略

  其中条件概率可以利用朴素（独立假设）来分解 multiply(P(Xi|Y))，而每一个因子的求解在最大似然假设下估计为数量占比（即在y下取得某个x的概率，用频率来估计他）

- 贝叶斯模型  argmax <y for all> P(Y|X = vector_x)  = argmax <y for all> P(Y) P(X = vector_x|Y)

4.在0-1损失下最大化后验概率相当于经验风险最小化。

5.平滑

- 为什么要平滑？

  因为条件独立假设导致了某个feature上很容易为0，那么我们直接估计他为0将导致后验概率为0。虽然这是完全符合最大似然的，但是我们的抽样是非常有限的（数据其实不能在各个维度上cover上的），我们还是想挽回一下这个y的类别，需要强行给他一个比较小的概率，不至于仅仅因为一个特征就导致机会完全为0。

- 拉普拉斯平滑：给这个feature的各种取值情况添加1或者一个较小值。

- 还有一些其他平滑方法。

#### 二、朴素贝叶斯程序实现

```python
# coding=utf-8

from copy import deepcopy


class NaiveBayes:
    def __init__(self):
        self._x = None  # 内部存储的训练集特征x
        self._y = None  # 内部存储训练集标签y
        self.dimension = None  # 特征维度
        self.shape = None  # 训练数据x的形状
        self._tags = None  # 可选的tag类别
        self._condition_probability = None  # 条件概率 # {feature_idx:{tag_y:{feature_value:probability}}}
        self._prior_probability = None  # 先验概率  # {y:probability}
        self._feature_value_sets = None  # 每个特征的取值范围 # {feature_idx:{values set}}
        pass

    def _check(self):
        """ 检查数据合法性，不符合条件就raise
        """
        if len(self._y) != self.shape[1]:
            raise ValueError("length of x and y not match")
        for i, xi in enumerate(self._x):
            if len(xi) != self.dimension:
                raise ValueError("data_%s:%s not much the dimension" % (i, xi))

    def _mk_feature_map(self):
        """ 构建先验概率字典，以及条件概率字典
        """
        features = list(zip(*self._x))
        self._prior_probability = {tag: 0.0 for tag in self._tags}  # {y:probability}
        self._condition_probability = {}  # {feature_idx:{tag_y:{feature_value:probability}}}
        self._feature_value_sets = {}  # {feature_idx:{values set}}
        for i, feature in enumerate(features):
            feature_value_set = set(feature)
            self._feature_value_sets[i] = feature_value_set
            # 拉普拉斯平滑
            y_dict = {tag: {v: 1.0 for v in feature_value_set} for tag in self._tags}
            for xi, yi in zip(feature, self._y):
                y_dict[yi][xi] += 1
            for tag in self._tags:
                tag_dict = y_dict[tag]  # shallow copy
                s = float(sum(tag_dict.values()))
                for key in tag_dict:
                    tag_dict[key] /= s
            self._condition_probability[i] = y_dict
        for yi in self._y:
            self._prior_probability[yi] += 1
        for key in self._prior_probability:
            self._prior_probability[key] /= self.shape[1]

    def fit(self, x, y):
        """ 拟合数据
        :param x: list<d-dimension obj tuple>训练数据集的特征
        :param y: list<obj>训练数据集的监督值
        """
        self._x = deepcopy(x)
        self._y = deepcopy(y)
        self.dimension = len(self._x[0])
        self.shape = self.dimension, len(self._x)
        self._check()
        self._tags = list(set(self._y))
        self._mk_feature_map()

    def _get_post_probability(self, x, tag):
        """ 计算后验概率
        :param x: tuple< obj> 测试数据样本点
        :param tag: obj 监督标签
        :return: float 后验概率
        """
        value = self._prior_probability[tag]
        for i in range(self.dimension):
            if x[i] not in self._feature_value_sets[i]: raise ValueError("not such value")
            value *= self._condition_probability[i][tag][x[i]]
        return value

    def predict(self, x):
        """ 输出预测标签
        :param x: tuple< obj> 测试数据样本点
        :return: obj 监督标签
        """
        if len(x) != self.dimension: raise ValueError("length not match")
        max_tag, max_post = self._tags[0], -1.0
        for tag, post in [(tag, self._get_post_probability(x, tag)) for tag in self._tags]:
            if post > max_post:
                max_tag = tag
                max_post = post
        return max_tag


def case():
    """ 测试用例
    :return:
    """
    import pandas as pd
    filename = "train2.csv"
    df = pd.read_csv(filename,
                     header=0,
                     encoding="utf-8",
                     sep=",").as_matrix()
    xs, ys = [], []
    for line in df:
        xs.append(tuple(line[:-1]))
        ys.append(line[-1])
    nb = NaiveBayes()
    nb.fit(xs, ys)
    print(nb.predict((1, 1, 3, 4)))
    print(nb.predict((1, 1, 2, 4)))


if __name__ == '__main__':
    case()
```

#### 三、拓展思考

- 朴素贝叶斯可以作为一种特征提取方法，原模型中使用的是特征相乘的方法。m分类下其实一个x提取了m乘以dimension个特征。那么完全可以将这些特征代入其他模型做特征选择。这种特征是抽象的。对于未来的数据，需要有一个特征查询表。
- 朴素贝叶斯和kNN还有决策树都很像：想象我们特征维度为1，那么这个模型是在这个特征上进行了协同过滤，相当于一个决策树桩，我们在该维度等于特定值时进行了最大表决。维度增大是一样的。

### I、隐马尔可夫(HMM)

[TODO 待复习]

1.HMM的两个假设

- 齐次马尔可夫假设(隐藏状态可以以概率矩阵A进行转移)
- 观测独立假设(每次观察量都可以从隐藏状态以概率矩阵B推导)


2.HMM模型

模型的状态转移不能直接观察到，需要以一定概率呈现。

lambda = (A,B,Pi)

其中A是隐藏状态转移矩阵，B是观察概率矩阵，Pi是初始状态。

3.HMM的三个问题

- **概率计算问题**：已知lambda，求特定观察值O的概率P(O|lambda)

  直接计算 或者 前向后向推导

- **学习问题**：已知O，求lambda

  监督学习 或者 EM（Baum-Welch）

- **预测问题(decoding)**: 已知lambda，求最优的O。

  维特比译码 。

### Y、《推荐系统实战》摘要

#### 一、推荐系统概念

1.动机

信息过载 （一个人能接受的信息是有限的，太多噪声带来了去噪压力）—> 物品的长尾（二八定律，只有20%的物品是畅销的，但是80%的商品却需要占用大量成本） —> 物品 <—> 用户

- 社会化推荐：让好友推荐
- 基于内容的推荐：content-based
- **协同过滤**：CF(collaborative Filtering):相似用户群推荐相似商品。

2.应用

- **电子商务**：量贩
- 电影电视音乐电台阅读:youtube
- 社交网络
- **基于位置的服务**
- 邮件、**广告**

3.性能评测

- 用户、物品提供者、提供推荐系统的网站
- **推荐不够新颖**：推荐了一本用户本来就要买的书（个人理解：更高的追求是去推荐那些用户潜意识下的东西而不是表层之上的意识流），好的推荐要能扩展用户的视野。（个人理解：花大力气去拓展用户的视野是否真的能长期给团队带来实际的利润，或者是相反呢？但是不试试怎么知道呢？）
- 离线实验（缺点：无法探测**点击转换率**。= (点击率，转换率)）
- 用户调查（原因：高预测准确率  != 用户满意度）(真正决定产品能长期走下去是把握用户满意度)
- 在线**AB测试**（缺点：周期长）

4.评测指标

- 用户满意度（调查、在线实验）
- 预测准确度、召回率等
- 覆盖率Coverage：排行榜只能推几个商品 — > entropy,gini —> 马太效应：强者越强，弱者越弱。很难覆盖。
- 多样性：最大熵，不在一棵树上吊死。
- 新颖性：有过行为的物品过滤掉
- 惊喜度
- 信任度（增加透明度）
- 实时性
- 健壮性（搜索引擎反作弊）
- 商业目标

5.评测维度

- 用户维度：人口统计学信息、活跃度、是否新用户
- 物品维度：属性信息、流行度、平均分，是否新加入物品
- 时间维度：工作日还是周末、白天还是晚上


#### 二、利用用户行为数据

- 显式反馈（点赞）
- 隐式反馈（浏览）
- 有无上下文（时间戳）

1.基于邻域的算法

- UserCF基于用户的协同过滤：找到和目标用户兴趣相似的用户。找到这个集合中用户喜欢的且用户没有听说过的物品推荐目标。

  惩罚热门物品。

- ItemCF基于物品的协同过滤，不通过物品属性，而通过用户对物品的行为的相似程度（Apriori).

2.隐语义模型LFM、LDA、pLSA。

- 对每个用户，正负样本要平衡，对每个用户负样本，要热门且未购。
- 困难：无法实时，需要扫描所有记录，可解释性差。

3.基于图的模型

连接数：Personal Rank 随机游走（走走看，走到哪）

#### 四、推荐系统冷启动

用户冷启动、物品冷启动、系统冷启动、提供非个性化推荐。

- 利用注册信息：人口统计学信息，用户兴趣的描述，站外数据。
- 选择合适的物品启动用户兴趣（比较热门，具有代表性、区分性、多样性）
- 利用物品的内容信息：用LDA使话题收敛到一个合理的分布上去。
- 利用专家系统和机器学习。
- 利用用户标签：表明物品是什么，物品的种类，谁拥有物品，表达用户的观点，用户相关用户任务：简单的算法，找到用户最多的标签，找到这个标签被打最多的物品，推荐给用户，改进TD-IDF。
- 数据稀疏性，标签清理（停止词、同义词）。

#### 五、利用上下文信息

1.时间上下文信息

- 时间效应：用户兴趣变化，物品生命周期、季节效应
- 系统时间：用户增长量、物品变化情况、用户访问情况
- 推荐系统的实时性、时间多样性

2.时间上下文推荐：最近最热门

3.时间段图模型

#### 六、利用社会网络数据

- 获取社交网络数据途径
- 电子邮件、用户注册信息、双向确定社会网络、单向关注、基于社区
- **好友推荐可以增加信任度，解决冷启动**
- 给用户推荐好友：interest based，social based，interest social， SONA

#### 七、推荐引擎架构

1.生成用户特征向量：用户行为的种类、用户行为产生的时间、用户行为的次数、物品的热门程度

2.特征— 物品相关推荐

3.过滤模块（用户已经产生过行为物品、候选物品以外的物品、质量差的物品）

4.排名模块（新颖性排名，多样性，时间多样性，用户反馈）

#### 八、评分预测问题

SVD（需要补全稀疏、计算复杂度高）—> SimonFunk的SVD分解




### Z、模型小结(用于填空题)

1.生成模型和判别模型

- 生成模型(先要算一遍联合概率)有：Naive Bayes，HMM
- 判别模型有：Perceptron，KNN，DT，LR，SVM，emsemble，NN（神经网）,CRF(条件场)。

2.损失函数

- 对数损失（LR）
- 平方损失（LSM，RF）
- 指数损失（Adaboost）
- 合页损失（SVM）
- 0-1损失（Perceptron，KNN，DT）
- 交叉熵:L(y,f) = -1/n sum(ylnf+(1-y)ln(1-f))  ； MSE是经验模型与高斯模型之间的交叉熵。

3.下降器：

一阶：Adam，AdaGrad，AdaDelta,RMSProP,SGD(Nesterov)

二阶：牛顿，BFGS，L-BFGS，共轭梯度。

4.收集多少数据合适呢？

测试集上的结果可以满足我们要求了，就可以了。

5.DL

- deep is better than fat.主要是Modularization参数变少了。虽然(BP时)梯度弥散，但是可以逐层训练。
- minibatch,batch-normalization,Relu(减小弥散，稀疏性，容易求导，用梯度下降法容易死掉，可以dropout等解决)，weight decay，dropout
- CNN卷积网（共用卷积核，去训练卷积核，假设图像相邻性）:Pooling(padding),Maxout
- RNN(LSTM,GRU):加了门电路，有记忆（序列前后关系）


- 替代损失函数
- 批算法
- 长期相关性（ESN）
- 近似梯度，无鞍牛顿法
- 预训练+微调。（模型迁移）
- 缺陷：优化的理论限制，DL的可解释性。



【to be continued @ 2018-08-23】